{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pdfplumber\n",
    "import os\n",
    "import glob\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFLoader:\n",
    "    def __init__(self, directory, glob_pattern=\"*.pdf\"):\n",
    "        self.directory = directory\n",
    "        self.glob_pattern = glob_pattern\n",
    "\n",
    "    def load(self):\n",
    "        documents = []\n",
    "        for pdf_path in glob.glob(os.path.join(self.directory, self.glob_pattern)):\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                full_text = \" \".join(page.extract_text() or '' for page in pdf.pages)\n",
    "                documents.append(full_text)\n",
    "        return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFLoader('./Input_text', glob_pattern=\"*.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, text):\n",
    "        self.page_content = text  # Mimicking the expected attribute\n",
    "        self.metadata = {}  # Assuming metadata is also expected\n",
    "\n",
    "# Wrap your extracted texts into Document instances\n",
    "documents = [Document(text) for text in loader.load()]\n",
    "\n",
    "# Now, use the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weijiasu/anaconda3/envs/chatbot_env/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ( \n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEM format is the Gene Expression Matrix file format used to store gene expression data. It includes information such as gene ID, coordinates, MID count, and optional cell ID. GEM files are used in the Stereo-seq analysis workflow to store gene expression matrices.\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\"What is GEM format?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GEF file format is designed for multi-dimensional data storage and high computation efficiency, while the GEM file format is used for gene expression matrices. RPI files are not specifically mentioned in the provided context, so the exact differences between GEF GEM and RPI files are not clear.\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\"What is the differences between GEF GEM and RPI files\")\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RPI v0.0.2 is an upgraded version of the RPI file format that supports storing and organizing multiple stained microscopy images in groups, with improved tissue recognition accuracy and performance. It also includes bug fixes related to version compatibility and gene expression distribution plot display. The RPI v0.0.2 is part of the STOmics Stereo-seq Analysis Workflow File Format Manual released in March 2023.\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\"What is the RPI v0.0.2\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
